{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kSjThhPNoo69"
      },
      "source": [
        "# Phase2 3 SHAP & Path Exaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qPX0nklS4i-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "import shap\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "folder_path = ''\n",
        "\n",
        "global NUM_LAYER\n",
        "NUM_LAYER = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAKvZG8Eg7AN"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_frts = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_frts, 10)\n",
        "    )\n",
        "\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(folder_path+'cifar10_resnet18.pt')) \n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf4Pp3wH2aNO"
      },
      "outputs": [],
      "source": [
        "def get_layer_shap(background, image):\n",
        "  #input\n",
        "  test_input = shap.DeepExplainer(model, background)\n",
        "  shap_input = np.asarray(test_input.shap_values(image, 1)[0]).squeeze()\n",
        "  \n",
        "  #conv1\n",
        "  test_conv1 = shap.DeepExplainer((model, model.conv1), background)\n",
        "  shap_conv1 = np.asarray(test_conv1.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #bn1\n",
        "  test_bn1 = shap.DeepExplainer((model, model.bn1), background)\n",
        "  shap_bn1 = np.asarray(test_bn1.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #maxpool\n",
        "  test_maxpool = shap.DeepExplainer((model, model.maxpool), background)\n",
        "  shap_maxpool = np.asarray(test_maxpool.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #layer1\n",
        "  test_layer1 = shap.DeepExplainer((model, model.layer1), background)\n",
        "  shap_layer1 = np.asarray(test_layer1.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #layer2\n",
        "  test_layer2 = shap.DeepExplainer((model, model.layer2), background)\n",
        "  shap_layer2 = np.asarray(test_layer2.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #layer3\n",
        "  test_layer3 = shap.DeepExplainer((model, model.layer3), background)\n",
        "  shap_layer3 = np.asarray(test_layer3.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #layer4\n",
        "  test_layer4 = shap.DeepExplainer((model, model.layer4), background)\n",
        "  shap_layer4 = np.asarray(test_layer4.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #avgpool\n",
        "  test_avgpool = shap.DeepExplainer((model, model.avgpool), background)\n",
        "  shap_avgpool = np.asarray(test_avgpool.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #fc\n",
        "  test_fc = shap.DeepExplainer((model, model.fc), background)\n",
        "  shap_fc = np.asarray(test_fc.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  return shap_input, shap_conv1, shap_bn1, shap_maxpool, shap_layer1, shap_layer2, shap_layer3, shap_layer4, shap_avgpool, shap_fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4oW_MdWoo7A"
      },
      "outputs": [],
      "source": [
        "def get_layer_most(layer_shap):\n",
        "  layer_most = layer_shap.copy()\n",
        "\n",
        "  for i in range(len(layer_shap)):\n",
        "    max = np.max(layer_most[i])\n",
        "    layer_most[i] = np.where(layer_most[i] == max, 1, 0)\n",
        "\n",
        "    if i == 0:\n",
        "      print(\"Critical neuron: \", np.sum(layer_most[i]))\n",
        "\n",
        "  return layer_most"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAUwd_jBoo7B"
      },
      "outputs": [],
      "source": [
        "def get_layer_quantile(layer_shap, alpha):\n",
        "  layer_quantile = layer_shap.copy()\n",
        "\n",
        "  for i in range(len(layer_shap)):\n",
        "    quantile = np.quantile(layer_quantile[i], alpha)\n",
        "    layer_quantile[i] = np.where(layer_quantile[i] < quantile, 0, 1)\n",
        "\n",
        "    if i == 0:\n",
        "      print(\"Critical neuron: \", np.sum(layer_quantile[i]))\n",
        "\n",
        "  return layer_quantile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def concatenate_shap_layer(layers_shap):\n",
        "  all_layer = np.empty(NUM_LAYER)\n",
        "\n",
        "  for i in range(len(layers_shap)):\n",
        "    f_layer = np.asarray(torch.flatten(torch.Tensor(layers_shap[i]), start_dim=1))\n",
        "    if i == 0:\n",
        "      all_layer = f_layer\n",
        "    else:\n",
        "      all_layer = np.concatenate((all_layer, f_layer), axis=1)\n",
        "  \n",
        "  return all_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJrTZZyiCYm9"
      },
      "outputs": [],
      "source": [
        "def concatenate_most_layer(layers_shap):\n",
        "  all_layer = np.empty(NUM_LAYER)\n",
        "\n",
        "  for i in range(len(layers_shap)):\n",
        "    f_layer = np.asarray(torch.flatten(torch.Tensor(get_layer_most(layers_shap[i])), start_dim=1))\n",
        "    if i == 0:\n",
        "      all_layer = f_layer\n",
        "    else:\n",
        "      all_layer = np.concatenate((all_layer, f_layer), axis=1)\n",
        "  \n",
        "  all_layer = all_layer.astype('bool')\n",
        "  \n",
        "  return all_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEDvbak2YlNK"
      },
      "outputs": [],
      "source": [
        "def concatenate_path_layer(alpha, layers_shap):\n",
        "  all_layer = np.empty(NUM_LAYER)\n",
        "\n",
        "  for i in range(len(layers_shap)):\n",
        "    f_layer = np.asarray(torch.flatten(torch.Tensor(get_layer_quantile(layers_shap[i], alpha)), start_dim=1))\n",
        "    if i == 0:\n",
        "      all_layer = f_layer\n",
        "    else:\n",
        "      all_layer = np.concatenate((all_layer, f_layer), axis=1)\n",
        "  \n",
        "  all_layer = all_layer.astype('bool')\n",
        "\n",
        "  print(alpha, \" All critical neuron: \", np.sum(all_layer)/len(layers_shap[0]))\n",
        "\n",
        "  return all_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atlKHjGLpaIX"
      },
      "outputs": [],
      "source": [
        "def generate_attack_layer(attack, num_background, alpha=[], approach=''):\n",
        "  print(attack)\n",
        "  images = np.load(folder_path + 'images_'+str(attack)+'.npy')\n",
        "  labels = np.load(folder_path + 'labels_'+str(attack)+'.npy')\n",
        "  images = torch.tensor(images)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  test_background = images[:num_background].to(device)\n",
        "  test_images = images[num_background:].to(device)\n",
        "  print(approach)\n",
        "  \n",
        "  layer = get_layer_shap(test_background, test_images)\n",
        "  \n",
        "  if approach == 'shap':\n",
        "    shap_layer = concatenate_shap_layer(layer)\n",
        "    np.save(folder_path + str(attack)+'_layer_shap.npy', shap_layer)\n",
        "    np.save(folder_path + str(attack)+'_pred_shap.npy', labels[num_background:])\n",
        "\n",
        "  elif approach == 'most':\n",
        "    most_layer = concatenate_most_layer(layer)\n",
        "    np.save(folder_path + str(attack)+'_layer_most.npy', most_layer)\n",
        "    np.save(folder_path + str(attack)+'_pred_most.npy', labels[num_background:])\n",
        "  \n",
        "  elif approach == 'path':\n",
        "    for test_alpha in alpha:\n",
        "      path_layer = concatenate_path_layer(test_alpha, layer)\n",
        "      np.save(folder_path + str(test_alpha)+ str(attack)+'_layer_path.npy', path_layer)\n",
        "      np.save(folder_path + str(test_alpha)+ str(attack)+'_pred_path.npy', labels[num_background:])\n",
        "  \n",
        "  elif approach =='multi':\n",
        "    print(\"shap\")\n",
        "    shap_layer = concatenate_shap_layer(layer)\n",
        "    np.save(folder_path + str(attack)+'_layer_shap.npy', shap_layer)\n",
        "    np.save(folder_path + str(attack)+'_pred_shap.npy', labels[num_background:])\n",
        "\n",
        "    print(\"most\")\n",
        "    most_layer = concatenate_most_layer(layer)\n",
        "    np.save(folder_path + str(attack)+'_layer_most.npy', most_layer)\n",
        "    np.save(folder_path + str(attack)+'_pred_most.npy', labels[num_background:])\n",
        "\n",
        "    for test_alpha in alpha:\n",
        "      print(test_alpha)\n",
        "      path_layer = concatenate_path_layer(test_alpha, layer)\n",
        "      np.save(folder_path + str(test_alpha)+ str(attack)+'_layer_path.npy', path_layer)\n",
        "      np.save(folder_path + str(test_alpha)+ str(attack)+'_pred_path.npy', labels[num_background:])\n",
        "\n",
        "  else:\n",
        "    print(\"Error approach\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf85DEYzzqA8"
      },
      "outputs": [],
      "source": [
        "def generate_attack_single(attack, num_background, layer='input'):\n",
        "  print(attack)\n",
        "  images = np.load(folder_path + 'images_'+str(attack)+'.npy')\n",
        "  labels = np.load(folder_path + 'labels_'+str(attack)+'.npy')\n",
        "  images = torch.tensor(images)\n",
        "  labels = torch.tensor(labels)\n",
        "  \n",
        "  test_background = images[:num_background].to(device)\n",
        "  test_images = images[num_background:].to(device)\n",
        "  print(layer)\n",
        "  \n",
        "  if layer == 'input':\n",
        "    test_layer = shap.DeepExplainer(model, test_background)\n",
        "  elif layer == 'layer4':\n",
        "    test_layer = shap.DeepExplainer((model, model.layer4), test_background)\n",
        "  elif layer == 'avgpool':\n",
        "    test_layer = shap.DeepExplainer((model, model.avgpool), test_background)\n",
        "  \n",
        "  shap_layer = np.asarray(test_layer.shap_values(test_images, 1)[0]).squeeze()\n",
        "\n",
        "  np.save(folder_path + str(attack)+'_'+str(layer)+'_shap.npy', shap_layer)\n",
        "  np.save(folder_path + str(attack)+'_'+str(layer)+'_pred.npy', labels[num_background:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q36It2tpH_3"
      },
      "outputs": [],
      "source": [
        "attack_name = ['pgd','deepfool','fgsm']\n",
        "\n",
        "for attack in attack_name:\n",
        "  generate_attack_layer(attack, 100, [0.05, 0.25, 0.5, 0.75, 0.95], approach = 'multi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attack_name = ['pgd','deepfool','fgsm']\n",
        "\n",
        "for attack in attack_name:\n",
        "  generate_attack_single(attack, 100, layer='input')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attack_name = ['pgd','deepfool','fgsm']\n",
        "\n",
        "for attack in attack_name:\n",
        "  generate_attack_single(attack, 100, layer='avgpool')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attack_name = ['pgd','deepfool','fgsm']\n",
        "\n",
        "for attack in attack_name:\n",
        "  generate_attack_single(attack, 100, layer='layer4')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
