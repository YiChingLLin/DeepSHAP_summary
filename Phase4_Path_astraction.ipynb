{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pydwVyS8Z-N6"
      },
      "source": [
        "# Phase4 Path Astraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qPX0nklS4i-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "\n",
        "import torchattacks\n",
        "import shap\n",
        "import sklearn\n",
        "from sklearn import utils\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "folder_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAKvZG8Eg7AN"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_frts = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(num_frts, 10)\n",
        "    )\n",
        "\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(folder_path+'cifar10_resnet18.pt')) \n",
        "model = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2_nM67aaWrV"
      },
      "outputs": [],
      "source": [
        "def load_concatenate_data():\n",
        "  data_deepfool = np.load(folder_path + 'images_deepfool.npy')\n",
        "  label_deepfool = np.load(folder_path + 'labels_deepfool.npy')\n",
        "  data_fgsm = np.load(folder_path + 'images_fgsm.npy')\n",
        "  label_fgsm = np.load(folder_path + 'labels_fgsm.npy')\n",
        "  data_pgd = np.load(folder_path + 'images_pgd.npy')\n",
        "  label_pgd = np.load(folder_path + 'labels_pgd.npy')\n",
        "  \n",
        "  \n",
        "  print(data_deepfool.shape, label_deepfool.shape)\n",
        "  print(data_fgsm.shape, label_fgsm.shape)\n",
        "  print(data_pgd.shape, label_pgd.shape)\n",
        "  \n",
        "  images = np.concatenate((data_deepfool, data_fgsm, data_pgd))\n",
        "  labels = np.concatenate((label_deepfool, label_fgsm, label_pgd))\n",
        "  images, labels = utils.shuffle(images, labels)\n",
        "\n",
        "  images = torch.tensor(images)\n",
        "  labels = torch.tensor(labels)\n",
        "  print(images.shape, labels.shape)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf4Pp3wH2aNO"
      },
      "outputs": [],
      "source": [
        "def get_layer_shap(background, image):\n",
        "  #input\n",
        "  test_input = shap.DeepExplainer(model, background)\n",
        "  shap_input = np.asarray(test_input.shap_values(image, 1)[0]).squeeze()\n",
        "  \n",
        "  #conv1\n",
        "  test_conv1 = shap.DeepExplainer((model, model.conv1), background)\n",
        "  shap_conv1 = np.asarray(test_conv1.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #bn1\n",
        "  test_bn1 = shap.DeepExplainer((model, model.bn1), background)\n",
        "  shap_bn1 = np.asarray(test_bn1.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #maxpool\n",
        "  test_maxpool = shap.DeepExplainer((model, model.maxpool), background)\n",
        "  shap_maxpool = np.asarray(test_maxpool.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #layer1\n",
        "  test_layer1 = shap.DeepExplainer((model, model.layer1), background)\n",
        "  shap_layer1 = np.asarray(test_layer1.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #layer2\n",
        "  test_layer2 = shap.DeepExplainer((model, model.layer2), background)\n",
        "  shap_layer2 = np.asarray(test_layer2.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #layer3\n",
        "  test_layer3 = shap.DeepExplainer((model, model.layer3), background)\n",
        "  shap_layer3 = np.asarray(test_layer3.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #layer4\n",
        "  test_layer4 = shap.DeepExplainer((model, model.layer4), background)\n",
        "  shap_layer4 = np.asarray(test_layer4.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #avgpool\n",
        "  test_avgpool = shap.DeepExplainer((model, model.avgpool), background)\n",
        "  shap_avgpool = np.asarray(test_avgpool.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  #fc\n",
        "  test_fc = shap.DeepExplainer((model, model.fc), background)\n",
        "  shap_fc = np.asarray(test_fc.shap_values(image, 1)[0]).squeeze()\n",
        "\n",
        "  return shap_input, shap_conv1, shap_bn1, shap_maxpool, shap_layer1, shap_layer2, shap_layer3, shap_layer4, shap_avgpool, shap_fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFhplRIcMX72"
      },
      "outputs": [],
      "source": [
        "def get_layer_quantile(layer_shap, alpha):\n",
        "  layer_quantile = layer_shap\n",
        "\n",
        "  for i in range(len(layer_shap)):\n",
        "    quantile = np.quantile(layer_quantile[i], alpha)\n",
        "    layer_quantile[i] = np.where(layer_quantile[i] < quantile, 0, 1)\n",
        "\n",
        "  return layer_quantile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcmRuFMZe5ts"
      },
      "outputs": [],
      "source": [
        "# normal / attack\n",
        "# compute each neuron weight: how many 1 in all\n",
        "def get_layer_merge(layer_shap, label):\n",
        "  layer_quantile = layer_shap\n",
        "\n",
        "  # normal\n",
        "  normal_index = np.where(label == 0)\n",
        "  normal_weight = np.sum(layer_quantile[normal_index], axis=0) / len(normal_index[0])\n",
        "\n",
        "  # adversarial\n",
        "  adversarial_index = np.where(label == 1)\n",
        "  adversarial_weight = np.sum(layer_quantile[adversarial_index], axis=0) / len(adversarial_index[0])\n",
        "\n",
        "  return normal_weight, adversarial_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDGtgC8Gig2J"
      },
      "outputs": [],
      "source": [
        "# use beta to select the common neuron\n",
        "def get_layer_common(weight, beta=0.95):\n",
        "  common = np.where(weight > beta, 1, 0)\n",
        "\n",
        "  return common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMsbu5cLbp_X"
      },
      "outputs": [],
      "source": [
        "def abstraction_merge_layer(all_layer_shap, label, alpha=0.9, merge_class=\"normal\"):  \n",
        "  layer = all_layer_shap #10,n,x,x,x\n",
        "\n",
        "  # layer_quantile  #n,x,x,x\n",
        "  if merge_class == \"normal\":\n",
        "    input, _ = get_layer_merge(get_layer_quantile(layer[0], alpha), label)\n",
        "    conv1, _ = get_layer_merge(get_layer_quantile(layer[1], alpha), label)\n",
        "    bn1, _ = get_layer_merge(get_layer_quantile(layer[2], alpha), label)\n",
        "    maxpool, _ = get_layer_merge(get_layer_quantile(layer[3], alpha), label)\n",
        "    layer1, _ = get_layer_merge(get_layer_quantile(layer[4], alpha), label)\n",
        "    layer2, _ = get_layer_merge(get_layer_quantile(layer[5], alpha), label)\n",
        "    layer3, _ = get_layer_merge(get_layer_quantile(layer[6], alpha), label)\n",
        "    layer4, _ = get_layer_merge(get_layer_quantile(layer[7], alpha), label)\n",
        "    avgpool, _ = get_layer_merge(get_layer_quantile(layer[8], alpha), label)\n",
        "    fc, _ = get_layer_merge(get_layer_quantile(layer[9], alpha), label)\n",
        "  \n",
        "  elif merge_class == \"adversarial\":\n",
        "    _, input = get_layer_merge(get_layer_quantile(layer[0], alpha), label)\n",
        "    _, conv1 = get_layer_merge(get_layer_quantile(layer[1], alpha), label)\n",
        "    _, bn1 = get_layer_merge(get_layer_quantile(layer[2], alpha), label)\n",
        "    _, maxpool = get_layer_merge(get_layer_quantile(layer[3], alpha), label)\n",
        "    _, layer1 = get_layer_merge(get_layer_quantile(layer[4], alpha), label)\n",
        "    _, layer2 = get_layer_merge(get_layer_quantile(layer[5], alpha), label)\n",
        "    _, layer3 = get_layer_merge(get_layer_quantile(layer[6], alpha), label)\n",
        "    _, layer4 = get_layer_merge(get_layer_quantile(layer[7], alpha), label)\n",
        "    _, avgpool = get_layer_merge(get_layer_quantile(layer[8], alpha), label)\n",
        "    _, fc = get_layer_merge(get_layer_quantile(layer[9], alpha), label)\n",
        "  \n",
        "  return input, conv1, bn1, maxpool, layer1, layer2, layer3, layer4, avgpool, fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmBS3BbNv28R"
      },
      "outputs": [],
      "source": [
        "def abstraction_path_layer(weight, beta=0.95):\n",
        "  input = get_layer_common(np.asarray(weight[0]), beta)\n",
        "  conv1 = get_layer_common(np.asarray(weight[1]), beta)\n",
        "  bn1 = get_layer_common(np.asarray(weight[2]), beta)\n",
        "  maxpool = get_layer_common(np.asarray(weight[3]), beta)\n",
        "  layer1 = get_layer_common(np.asarray(weight[4]), beta)\n",
        "  layer2 = get_layer_common(np.asarray(weight[5]), beta)\n",
        "  layer3 = get_layer_common(np.asarray(weight[6]), beta)\n",
        "  layer4 = get_layer_common(np.asarray(weight[7]), beta)\n",
        "  avgpool = get_layer_common(np.asarray(weight[8]), beta)\n",
        "  fc = get_layer_common(np.asarray(weight[9]), beta)\n",
        "\n",
        "  return input, conv1, bn1, maxpool, layer1, layer2, layer3, layer4, avgpool, fc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def abstraction_plot(path, comment='n'):\n",
        "  for i in range(len(path)):\n",
        "    data = path[i]\n",
        "    print(path[i].shape)\n",
        "\n",
        "    if len(data.shape) == 3:\n",
        "      fig = plt.figure()\n",
        "      ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "      x, y, z = data.nonzero()\n",
        "      ax.scatter(x, y, z, alpha=1)\n",
        "      ax.set_title('layer_'+str(i))\n",
        "      ax.set_xlim(0, len(path[i]))\n",
        "      ax.set_ylim(0, len(path[i][0]))\n",
        "      ax.set_zlim(0, len(path[i][0][0]))\n",
        "      ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "      ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "      ax.zaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "      plt.savefig(folder_path+str(i)+str(comment)+'.png')\n",
        "    \n",
        "    elif len(data.shape) == 2:\n",
        "      ax = plt.figure(figsize=(4.7,4.7)).gca()\n",
        "\n",
        "      x, y = data.nonzero()\n",
        "      ax.scatter(x, y, alpha=1)\n",
        "      ax.set_title('layer_'+str(i))\n",
        "      ax.set_xlim(0, len(data))\n",
        "      ax.set_ylim(0, len(data[0]))\n",
        "      ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "      ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "      plt.savefig(folder_path+str(i)+str(comment)+'.png')\n",
        "\n",
        "    elif len(data.shape) == 1:\n",
        "      ax = plt.figure(figsize=(4.7,4.7)).gca()\n",
        "\n",
        "      data = np.expand_dims(path[i], axis=1)\n",
        "      x, y = data.nonzero()\n",
        "      ax.scatter(x, y, alpha=1)\n",
        "      ax.set_title('layer_'+str(i))\n",
        "      ax.set_xlim(0, len(data))\n",
        "      ax.set_yticks([0, len(data[0])])\n",
        "      ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "      ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "      plt.savefig(folder_path+str(i)+str(comment)+'.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4qfVYgBbnyK"
      },
      "outputs": [],
      "source": [
        "def generate_class_abstraction(num_background, alpha=0, beta=[], plot = True):\n",
        "  images, labels = load_concatenate_data()\n",
        "  test_background = images[:num_background].to(device)\n",
        "  test_images = images[num_background:].to(device)\n",
        "  test_alpha = alpha\n",
        "\n",
        "  layers_shap = get_layer_shap(test_background, test_images) #10,n,x,x,x\n",
        "\n",
        "  normal_lw = abstraction_merge_layer(layers_shap, labels[num_background:], alpha=test_alpha, merge_class=\"normal\")\n",
        "  adv_lw = abstraction_merge_layer(layers_shap, labels[num_background:], alpha=test_alpha, merge_class=\"adversarial\")\n",
        "\n",
        "  for test_beta in beta:\n",
        "    print(test_beta)\n",
        "    normal_lpath = abstraction_path_layer(normal_lw, beta=test_beta)\n",
        "    adv_lpath = abstraction_path_layer(adv_lw, beta=test_beta)\n",
        "\n",
        "    np.save(folder_path+'normal_'+str(test_alpha)+'_'+str(test_beta)+'.npy', normal_lpath)\n",
        "    np.save(folder_path+'adversarial_'+str(test_alpha)+'_'+str(test_beta)+'.npy', adv_lpath)\n",
        "\n",
        "    print(\"Number of common critical neuron in normal\")\n",
        "    for i in range(len(normal_lw)):\n",
        "      print(np.sum(normal_lpath[i]))\n",
        "\n",
        "    print(\"Number of common critical neuron in adversarial\")\n",
        "    for i in range(len(adv_lw)):\n",
        "      print(np.sum(adv_lpath[i]))\n",
        "\n",
        "    if plot:\n",
        "      abstraction_plot(normal_lpath, comment='nor_'+str(test_alpha)+'_'+str(test_beta))\n",
        "      abstraction_plot(adv_lpath, comment='adv_'+str(test_alpha)+'_'+str(test_beta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lPuOnJUQf9uo",
        "outputId": "fa2dd4c1-e03c-4687-c762-968f50bc69f3"
      },
      "outputs": [],
      "source": [
        "generate_class_abstraction(100, 0.95, [0.7], plot = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
